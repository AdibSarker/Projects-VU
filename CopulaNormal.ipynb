{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de cel hier onder te runnen moet er een package geinstalleerd worden via anaconda prompt. Deze package zorgt ervoor dat we functies uit andere scripts kunnen gerbuiken in dit script.\n",
    "<break>\n",
    "Tik het volgende in anaconda prompt:\n",
    "<br \\>\n",
    "**pip install ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.Dataset import getdata\n",
    "from ipynb.fs.full.Dataset import getreturns\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as st\n",
    "from scipy.special import ndtri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hier onder wordt de dataset verkregen. Ik gebruik 2010 tot en met 2015 als mijn in-sample data.\n",
    "<break>\n",
    "Hiervoor gebruik een functie die in een ander script (Dataset) is geschreven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getreturns()\n",
    "mInSampleReturns = df.loc[:\"2015\"]\n",
    "mOutSampleReturns = df.loc[\"2016\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_GARCH_Normal(vReturns):\n",
    "    dOmega = 0.1\n",
    "    dAlpha = 0.1\n",
    "    dBeta = 0.8    \n",
    "    vTheta = np.array([dOmega, dAlpha, dBeta])\n",
    "    \n",
    "    def LL_GARCH_Normal(vTheta,returns):\n",
    "        dOmega = vTheta[0]\n",
    "        dAlpha = vTheta[1]\n",
    "        dBeta  = vTheta[2]\n",
    "        iT=len(returns)\n",
    "        vH=np.zeros(iT)\n",
    "        \n",
    "        for t in range(iT):\n",
    "            if t == 0:\n",
    "                vH[t] = np.var(returns) \n",
    "            else:\n",
    "                vH[t] = dOmega + dAlpha*returns[t-1]**2 + dBeta * vH[t-1]    \n",
    "        \n",
    "        vLogPdf = -0.5 * np.log( 2 * np.pi * vH[1:] ) - 0.5 * ( returns[1:]**2 / vH[1:] )\n",
    "        return -np.sum(vLogPdf)\n",
    "    \n",
    "    def Optimizer(returns, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0, 1), (0, 1), (0, 1))\n",
    "    result=Optimizer(vReturns, vTheta, LL_GARCH_Normal, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2516.193369258651\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "[ 0.05195353  0.09350152  0.87921127]\n",
      "-2516.193369258651\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter1_N,likelihood1_N,success1_N)=Parameters_GARCH_Normal(np.array(mInSampleReturns.iloc[:,0]))\n",
    "print(parameter1_N)\n",
    "print(likelihood1_N)\n",
    "print(success1_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2238.592048513497\n",
      "            Iterations: 12\n",
      "            Function evaluations: 69\n",
      "            Gradient evaluations: 12\n",
      "[ 0.03347424  0.09929269  0.8768056 ]\n",
      "-2238.592048513497\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter2_N,likelihood2_N,success2_N)=Parameters_GARCH_Normal(np.array(mInSampleReturns.iloc[:,1]))\n",
    "print(parameter2_N)\n",
    "print(likelihood2_N)\n",
    "print(success2_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hier schat ik de waardes van de sigma's over tijd voor alle 2 de tijdreeksen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeSigma2GARCH(vTheta1_N,vTheta2_N,mReturns):\n",
    "    iT = mReturns.shape[1]\n",
    "    iDimension = mReturns.shape[0]\n",
    "    mH = np.zeros((iDimension,iT))\n",
    "    dOmega1 = vTheta1_N[0]\n",
    "    dOmega2 = vTheta2_N[0]\n",
    "    dAlpha1 = vTheta1_N[1]\n",
    "    dAlpha2 = vTheta2_N[1]\n",
    "    dBeta1 = vTheta1_N[2]\n",
    "    dBeta2 = vTheta2_N[2]\n",
    "    for t in range(iT):\n",
    "        if t==0:\n",
    "            mH[0,t]=np.var(mReturns[0,:])\n",
    "            mH[1,t]=np.var(mReturns[1,:])\n",
    "        else:\n",
    "            mH[0,t]=dOmega1 + dAlpha1 * mReturns[0,t-1]**2 + dBeta1 * mH[0,t-1]\n",
    "            mH[1,t]=dOmega2 + dAlpha2 * mReturns[1,t-1]**2 + dBeta2 * mH[1,t-1]\n",
    "    return mH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mSigma2=ComputeSigma2GARCH(parameter1_N,parameter2_N,np.array(mInSampleReturns).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copula part\n",
    "\n",
    "Vanaf hieronder zal ik de copula LL gaan uitwerken. Eerst moet ik de PIT transformatie toepassen op de returns. Hierbij moet ik de kans berekenen dat:\n",
    "$$ P(Y_t<y_t)=u_t \\quad Y_t\\sim \\text{N}(0,\\sigma_t^2) $$\n",
    "Waarbij $Y_t$ een stochast is en $y_t$ de realisatie. We gaan een ingebouwde functie (st.norm.cdf) gebruiken om deze kans te berekenen. \n",
    "<break>\n",
    "De log-pdf op een bepaald tijdstip ziet er als volgt uit:\n",
    "$$-\\frac{1}{2}\\log\\left(\\left|R\\right|\\right)-\\frac{1}{2}x_t'\\left(R^{-1}-I\\right)x_t$$\n",
    "\n",
    "- x is gedefinieerd als:\n",
    "$$x_t=\\begin{pmatrix} \\Phi^{-1}(u_{1t})\\\\ \\Phi^{-1}(u_{2t})\\end{pmatrix}$$\n",
    "$\\Phi^{-1}(u_{it})$ wordt verkregen met de functie st.norm.ppf(), waarbij $u_{it}$ de PIT is van een tijdreeks\n",
    "\n",
    "- $R$ is als volgt gedefinieerd:\n",
    "\n",
    "$$R=\\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}$$\n",
    "<break>\n",
    "\n",
    "- de log-likelihood ziet er dan als volgt uit:\n",
    "$$\\sum_{t=1}^T-\\frac{1}{2}\\log\\left(\\left|R\\right|\\right)-\\frac{1}{2}x_t'\\left(R^{-1}-I\\right)x_t$$\n",
    "waarbij T het totaal aantal in-sample returns zijn\n",
    "\n",
    "- de parameter die log-likelihood wordt geoptimaliseerd wrt $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Copula_Normal(mReturns,mH):\n",
    "    dRho12 = 0.2\n",
    "    vTheta = np.array([dRho12])\n",
    "    \n",
    "    def LL_Copula_Normal(vTheta,mReturns,mH):\n",
    "        dRho12 = vTheta[0]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mUt = st.norm.cdf(mReturns, loc=np.zeros(mReturns.shape), scale=np.sqrt(mH))\n",
    "        mR = np.ones((iDimension,iDimension))\n",
    "        mR[1,0] = dRho12\n",
    "        mR[0,1] = dRho12\n",
    "        mI=np.identity(iDimension)\n",
    "        \n",
    "        dSum=0\n",
    "        \n",
    "        for t in range(1,iT):\n",
    "            vU_t = mUt[:,t]\n",
    "            vU_t = vU_t.reshape((iDimension,1))\n",
    "            vX=st.norm.ppf(vU_t)\n",
    "            dLogLikelihood = -0.5 * np.log(det(mR)) - 0.5 * vX.T @ (inv(mR)-mI) @ vX\n",
    "            dSum += np.asscalar(dLogLikelihood) \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((-0.9999999, 0.9999999),)\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Copula_Normal, bounds)\n",
    "    return result.x, -result.fun, result.success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1489.8786033474553\n",
      "            Iterations: 21\n",
      "            Function evaluations: 71\n",
      "            Gradient evaluations: 19\n",
      "[ 0.92608295]\n",
      "1489.8786033474553\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(dRho,LL_Copula_N,success_Copula_N)=Parameters_Copula_Normal(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(dRho)\n",
    "print(LL_Copula_N)\n",
    "print(success_Copula_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AIC(vTheta1, vTheta2, vTheta3, dLL1, dLL2, dLL3):\n",
    "    iK=len(vTheta1)+len(vTheta2)+len(vTheta3)\n",
    "    dLL=dLL1+dLL2+dLL3\n",
    "    dAIC= 2*iK-2*dLL\n",
    "    print(dAIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6543.813628849384\n"
     ]
    }
   ],
   "source": [
    "AIC(parameter1_N,parameter2_N,dRho, likelihood1_N, likelihood2_N , LL_Copula_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LL_GARCH_Normal(vTheta,returns):\n",
    "    dOmega = vTheta[0]\n",
    "    dAlpha = vTheta[1]\n",
    "    dBeta  = vTheta[2]\n",
    "    iT=len(returns)\n",
    "    vH=np.zeros(iT)\n",
    "\n",
    "    for t in range(iT):\n",
    "        if t == 0:\n",
    "            vH[t] = np.var(returns) \n",
    "        else:\n",
    "            vH[t] = dOmega + dAlpha*returns[t-1]**2 + dBeta * vH[t-1]    \n",
    "\n",
    "    vLogPdf = -0.5 * np.log( 2 * np.pi * vH[1:] ) - 0.5 * ( returns[1:]**2 / vH[1:] )\n",
    "    return np.sum(vLogPdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def LL_Copula_Normal(vTheta,mReturns,mH):\n",
    "        dRho12 = vTheta[0]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "        mR = np.ones((iDimension,iDimension))\n",
    "        mR[1,0] = dRho12\n",
    "        mR[0,1] = dRho12\n",
    "        mI=np.identity(iDimension)\n",
    "        \n",
    "        dSum=0\n",
    "        \n",
    "        for t in range(0,iT):\n",
    "            vEpsilon_t = mEpsilon[:,t]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            vProbability=st.norm.cdf(vEpsilon_t)\n",
    "            vQuantiles=st.norm.ppf(vProbability)\n",
    "            dLogLikelihood = -0.5 * np.log(det(mR)) - 0.5 * vQuantiles.T @ (inv(mR)-mI) @ vQuantiles\n",
    "            dSum += np.asscalar(dLogLikelihood) \n",
    "        return dSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogarithmicScore(vTheta1,vTheta2,vTheta3,mOutSampleReturns):\n",
    "    dLL1 = LL_GARCH_Normal(vTheta1,np.array(mOutSampleReturns.iloc[:,0]))\n",
    "    dLL2 = LL_GARCH_Normal(vTheta2,np.array(mOutSampleReturns.iloc[:,1]))\n",
    "    mVariance = ComputeSigma2GARCH(vTheta1,vTheta2,np.array(mOutSampleReturns).T)\n",
    "    dLL3 = LL_Copula_Normal(vTheta3,np.array(mOutSampleReturns).T,mVariance)\n",
    "    dLogScore = dLL1+dLL2+dLL3\n",
    "    \n",
    "    return dLogScore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dLogScore = LogarithmicScore(parameter1_N,parameter2_N,dRho,mOutSampleReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1612.09475464\n"
     ]
    }
   ],
   "source": [
    "print(dLogScore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
