{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In dit script gaan we het CCC model en het DCC model schatten met student-t verdeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de cel hier onder te runnen moet er een package geinstalleerd worden via anaconda prompt. Deze package zorgt ervoor dat we functies uit andere scripts kunnen gerbuiken in dit script.\n",
    "<break>\n",
    "Tik het volgende in anaconda prompt:\n",
    "<br \\>\n",
    "**pip install ipynb**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.Dataset import getdata\n",
    "from ipynb.fs.full.Dataset import getreturns\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gammaln\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getreturns()\n",
    "mInSampleReturns = df.loc[:\"2015\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de CCC de DCC modellen te schatten kan de log-likelihood opgedeeld worden in 2 delen.\n",
    "- Schat univariate GARCH(1,1) modellen los van elkaar met student-t verdeling.\n",
    "- schat daarna de correlatie term met de parameters die je in stap 1 hebt berekend. \n",
    "\n",
    "\n",
    "<break>\n",
    "De univariate student-t distribution van de GARCH modellen zien er als volgt uit:\n",
    "\n",
    "$$    LL=\\sum_{t=2}^T\\log\\left( \\Gamma\\left(\\frac{\\nu+1}{2}\\right)\\right)-\\log\\left( \\Gamma\\left(\\frac{\\nu}{2}\\right)\\right)-\\frac{1}{2}\\log\\left(\\pi\\left(\\nu-2\\right)\\sigma_t^2\\right)-\\frac{\\nu+1}{2}\\log\\left(1+\\frac{y_t^2}{(\\nu-2)\\sigma_t^2}\\right)$$\n",
    "Waarbij $\\sigma_t^2$ is gedefinieerd als\n",
    "$$\\sigma_t^2=\\omega+\\alpha y_t^2 + \\beta\\sigma_{t-1}^2$$\n",
    "In de cel hieronder is een functie geschreven om een losse GARCH(1,1) model te schatten. De parameters die we hierbij moeten schatten zijn:\n",
    "\n",
    "- [$\\omega,\\alpha,\\beta,\\nu$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_GARCH_Student(vReturns):\n",
    "    dOmega = 0.1\n",
    "    dAlpha = 0.1\n",
    "    dBeta = 0.8\n",
    "    dNu = 4.2\n",
    "    vTheta = np.array([dOmega, dAlpha, dBeta, dNu])\n",
    "    \n",
    "    def LL_GARCH_Student(vTheta,returns):\n",
    "        dOmega = vTheta[0]\n",
    "        dAlpha = vTheta[1]\n",
    "        dBeta  = vTheta[2]\n",
    "        dNu = vTheta[3]\n",
    "        iT=len(returns)\n",
    "        vH=np.zeros(iT)\n",
    "        \n",
    "        for t in range(iT):\n",
    "            if t == 0:\n",
    "                vH[t] = np.var(returns) \n",
    "            else:\n",
    "                vH[t] = dOmega + dAlpha*returns[t-1]**2 + dBeta * vH[t-1]    \n",
    "        \n",
    "        vLogPdf = gammaln( (dNu+1)/2 )-gammaln( dNu/2 ) - 0.5*np.log( np.pi*(dNu-2)*vH[1:] ) \\\n",
    "                - 0.5 * (dNu+1) * np.log( 1 + ( vReturns[1:]**2 / ( (dNu-2)*vH[1:] ) ) )\n",
    "        return -np.sum(vLogPdf)\n",
    "    \n",
    "    def Optimizer(returns, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0, 1), (0, 1), (0, 1), (2.1,50))\n",
    "    result=Optimizer(vReturns, vTheta, LL_GARCH_Student, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2492.9007501403294\n",
      "            Iterations: 16\n",
      "            Function evaluations: 107\n",
      "            Gradient evaluations: 16\n",
      "[ 0.04129691  0.09040065  0.89042978  6.9246734 ]\n",
      "-2492.9007501403294\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter1_Stud,likelihood1_Stud,success1_Stud)=Parameters_GARCH_Student(np.array(mInSampleReturns.iloc[:,0]))\n",
    "print(parameter1_Stud)\n",
    "print(likelihood1_Stud)\n",
    "print(success1_Stud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2217.307544488237\n",
      "            Iterations: 16\n",
      "            Function evaluations: 108\n",
      "            Gradient evaluations: 16\n",
      "[ 0.02623554  0.09365917  0.89023515  6.98573207]\n",
      "-2217.307544488237\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter2_Stud,likelihood2_Stud,success2_Stud)=Parameters_GARCH_Student(np.array(mInSampleReturns.iloc[:,1]))\n",
    "print(parameter2_Stud)\n",
    "print(likelihood2_Stud)\n",
    "print(success2_Stud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeSigma2GARCH(vTheta1,vTheta2,mReturns):\n",
    "    iT = mReturns.shape[1]\n",
    "    iDimension = mReturns.shape[0]\n",
    "    mH = np.zeros((iDimension,iT))\n",
    "    dOmega1 = vTheta1[0]\n",
    "    dOmega2 = vTheta2[0]\n",
    "    dAlpha1 = vTheta1[1]\n",
    "    dAlpha2 = vTheta2[1]\n",
    "    dBeta1 = vTheta1[2]\n",
    "    dBeta2 = vTheta2[2]\n",
    "    for t in range(iT):\n",
    "        if t==0:\n",
    "            mH[0,t]=np.var(mReturns[0,:])\n",
    "            mH[1,t]=np.var(mReturns[1,:])\n",
    "        else:\n",
    "            mH[0,t]=dOmega1 + dAlpha1 * mReturns[0,t-1]**2 + dBeta1 * mH[0,t-1]\n",
    "            mH[1,t]=dOmega2 + dAlpha2 * mReturns[1,t-1]**2 + dBeta2 * mH[1,t-1]\n",
    "    return mH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mSigma2=ComputeSigma2GARCH(parameter1_Stud,parameter2_Stud,np.array(mInSampleReturns).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder maximaliseren we de log-likelihood van de correlatie term van het CCC model. \n",
    "De log-likelihood van de correlatie term ziet er als volgt uit:\n",
    "$$\\sum_{t=2}^{T}\\left(\\log\\Gamma\\left(\\frac{\\nu+n}{2}\\right)-\\log\\Gamma\\left(\\frac{\\nu}{2}\\right)-\\frac{n}{2}\\log(\\pi(\\nu-2))-\\frac{1}{2}\\log\\left(|D_t|^2\\right)-\\frac{1}{2}\\log\\left(|R_t|\\right)-\\left(\\frac{\\nu+n}{2}\\right)\\log\\left(1+\\frac{\\epsilon_t'R_t^{-1}\\epsilon_t}{\\nu-2}\\right)\\right)$$\n",
    "- waarbij R is gedefinieerd als:\n",
    "$$R=\\begin{pmatrix} 1 & \\rho_{12} \\\\ \\rho_{12} & 1 \\end{pmatrix}$$\n",
    "- $\\epsilon_t$ als:\n",
    "$$\\epsilon_t=\\begin{pmatrix} \\epsilon_{1t} \\\\ \\epsilon_{2t}\\end{pmatrix}$$\n",
    "- $\\epsilon_{it}$ is verkregen door:\n",
    "$$\\epsilon_{it}=\\frac{y_{it}}{\\sigma_{it}}$$\n",
    "De log-likelihood willen we maximaliseren wrt $\\rho_{12}$ en $\\nu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_StudentCCC(mReturns,mH):\n",
    "    dRho12 = 0.2\n",
    "    dNu = 4.2\n",
    "    vTheta = np.array([dRho12, dNu])\n",
    "    \n",
    "    def LL_Correlation_StudentCCC(vTheta,mReturns,mH):\n",
    "        dRho12 = vTheta[0]\n",
    "        dNu = vTheta[1]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "        mR = np.ones((iDimension,iDimension))\n",
    "        mR[1,0] = dRho12\n",
    "        mR[0,1] = dRho12\n",
    "        \n",
    "        dSum=0\n",
    "        \n",
    "        for t in range(1,iT):\n",
    "            mD_t=np.diag(np.sqrt(mH[:,t]))\n",
    "            vEpsilon_t = mEpsilon[:,t]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            dLogLikelihood = gammaln((iDimension+dNu)/2) - gammaln(dNu/2) - iDimension/2 * np.log(np.pi*(dNu-2)) \\\n",
    "                            -0.5*np.log( det(mD_t)**2 ) - 0.5 * np.log( det(mR) ) - ( (dNu+iDimension)/2 ) * \\\n",
    "                            np.log(1+ ( ( vEpsilon_t.T @ inv(mR) @vEpsilon_t ) / (dNu-2) ) )\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "  \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((-0.9999999, 0.9999999),(2.1,50))\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_StudentCCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 3215.4318508079887\n",
      "            Iterations: 29\n",
      "            Function evaluations: 129\n",
      "            Gradient evaluations: 28\n",
      "[ 0.92582585  7.03458001]\n",
      "-3215.4318508079887\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(vParameters_CCC,LL_Correlation_CCC,success_Corr_CCC)=Parameters_Correlation_StudentCCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(vParameters_CCC)\n",
    "print(LL_Correlation_CCC)\n",
    "print(success_Corr_CCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier gaan we de correlatie term van het DCC model schatten. De log-likelihood ziet er als volgt uit:\n",
    "$$\\sum_{t=2}^{T}\\left(\\log\\Gamma\\left(\\frac{\\nu+n}{2}\\right)-\\log\\Gamma\\left(\\frac{\\nu}{2}\\right)-\\frac{n}{2}\\log(\\pi(\\nu-2))-\\frac{1}{2}\\log\\left(|D_t|^2\\right)-\\frac{1}{2}\\log\\left(|R_t|\\right)-\\left(\\frac{\\nu+n}{2}\\right)\\log\\left(1+\\frac{\\epsilon_t'R_t^{-1}\\epsilon_t}{\\nu-2}\\right)\\right)$$\n",
    "- Waarbij $R_t$ is gedefinieerd als:\n",
    "$$ R_t=\\text{diag}(Q_t)^{\\frac{-1}{2}}Q_t\\text{diag}(Q_t)^{\\frac{-1}{2}}$$\n",
    "- Q_t is gedefinieerd als:\n",
    "$$Q_t=(1-A-B)S + A\\epsilon_{t-1}\\epsilon_{t-1}' + BQ_{t-1}$$\n",
    "-S is gedefinieerd als:\n",
    "$$S=\\frac{1}{T}\\sum_{t=1}^{T}\\epsilon_t\\epsilon_t'$$\n",
    "verder gebruik ik als initialisatie van $Q_1=S$\n",
    "<break>\n",
    "- De $diag(Q_t)^\\frac{-1}{2}$ is een diagonaal matrix waarbij de elementen op de diagonaal matrix hetzelfde zijn als die van $Q_t$ alleen dan nog in de wortel genomen\n",
    "- In andere woorden:\n",
    "$$diag(Q_t)^{-\\frac{1}{2}}=\\begin{pmatrix} \\sqrt(q_{11t}) & 0 \\\\ 0 & \\sqrt(q_{22t}) \\end{pmatrix}^{-1}, Q_t=\\begin{pmatrix} q_{11t} & q_{12t} \\\\ q_{21t} & q_{22t} \\end{pmatrix} $$\n",
    "- De log-likelihood wordt gemaximaliseerd wrt A, B, $\\nu$, waarbij A en B getallen zijn die positief moeten zijn en $\\nu>2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_StudentDCC(mReturns,mH):\n",
    "    dA = 0.2\n",
    "    dB = 0.7\n",
    "    dNu = 4.2\n",
    "    vTheta = np.array([dA,dB,dNu])\n",
    "    \n",
    "    def LL_Correlation_StudentDCC(vTheta,mReturns,mH):\n",
    "        dA = vTheta[0]\n",
    "        dB = vTheta[1]\n",
    "        dNu = vTheta[2]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "\n",
    "        mS_sum = np.zeros((iDimension,iDimension))\n",
    "        for i in range(iT):\n",
    "            vEpsilon_t = mEpsilon[:,i]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            mS_sum += vEpsilon_t @ vEpsilon_t.T\n",
    "        \n",
    "        mS = mS_sum / iT\n",
    "        mQ_old=np.copy(mS)\n",
    "        \n",
    "        dSum=0\n",
    "        for t in range(1,iT):\n",
    "            mD_t=np.diag(np.sqrt(mH[:,t]))\n",
    "            vEpsilon_lag=mEpsilon[:,t-1]\n",
    "            vEpsilon_lag=vEpsilon_lag.reshape((iDimension,1))\n",
    "            vEpsilon=mEpsilon[:,t]\n",
    "            vEpsilon=vEpsilon.reshape((iDimension,1))\n",
    "            \n",
    "            mQ = (1-dA-dB) * mS + dA * vEpsilon_lag @ vEpsilon_lag.T + dB * mQ_old \n",
    "            mQ_diagonal = np.sqrt(np.diagonal(mQ))\n",
    "            mR_t= inv(np.diag(mQ_diagonal)) @ mQ @ inv(np.diag(mQ_diagonal)) \n",
    "            \n",
    "            dLogLikelihood = gammaln((iDimension+dNu)/2) - gammaln(dNu/2) - iDimension/2 * np.log(np.pi*(dNu-2)) \\\n",
    "                            -0.5*np.log( det(mD_t)**2 ) - 0.5 * np.log( det(mR_t) ) - ( (dNu+iDimension)/2 ) * \\\n",
    "                            np.log(1+ ( ( vEpsilon.T @ inv(mR_t) @vEpsilon ) / (dNu-2) ) )\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "            mQ_old=mQ \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0.0001, 0.9999), (0.0001,0.9999), (2.1,50))\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_StudentDCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 3173.9248196202416\n",
      "            Iterations: 15\n",
      "            Function evaluations: 99\n",
      "            Gradient evaluations: 15\n",
      "[ 0.05806218  0.90943246  7.52368661]\n",
      "-3173.9248196202416\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(vParametersDCC,LL_Correlation_DCC,success_Corr_DCC)=Parameters_Correlation_StudentDCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(vParametersDCC)\n",
    "print(LL_Correlation_DCC)\n",
    "print(success_Corr_DCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier gaan we de correlatie term van het DCC model schatten. De log-likelihood ziet er als volgt uit:\n",
    "$$\\sum_{t=2}^{T}\\left(\\log\\Gamma\\left(\\frac{\\nu+n}{2}\\right)-\\log\\Gamma\\left(\\frac{\\nu}{2}\\right)-\\frac{n}{2}\\log(\\pi(\\nu-2))-\\frac{1}{2}\\log\\left(|D_t|^2\\right)-\\frac{1}{2}\\log\\left(|R_t|\\right)-\\left(\\frac{\\nu+n}{2}\\right)\\log\\left(1+\\frac{\\epsilon_t'R_t^{-1}\\epsilon_t}{\\nu-2}\\right)\\right)$$\n",
    "- Waarbij $R_t$ is gedefinieerd als:\n",
    "$$ R_t=\\text{diag}(Q_t)^{\\frac{-1}{2}}Q_t\\text{diag}(Q_t)^{\\frac{-1}{2}}$$\n",
    "- Q_t is gedefinieerd als:\n",
    "$$Q_t=(1-A-B)S -G\\bar{N} + A\\epsilon_{t-1}\\epsilon_{t-1}' + Gn_{t-1}n_{t-1}' + BQ_{t-1}$$\n",
    "- S is gedefinieerd als:\n",
    "$$S=\\frac{1}{T}\\sum_{t=1}^{T}\\epsilon_t\\epsilon_t'$$\n",
    "verder gebruik ik als initialisatie voor $Q_1=S$\n",
    "<break>\n",
    "- n_{t-1} is gedefinieerd als: \n",
    "$$\n",
    "n_{t-1}=\\mathbb{1}(\\epsilon_{t-1})\\odot \\epsilon_{t-1}\n",
    "\\\\\n",
    "\\mathbb{1}=\\begin{cases}\n",
    "1&\\text{if $\\epsilon_{t-1}<0$}\\\\\n",
    "0&\\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- Hierbij is $\\bar{N}$ gedefinieerd als:\n",
    "$$\\bar{N}=\\frac{1}{T}\\sum_{t=1}^{T}n_tn_t'\n",
    "$$\n",
    "Verder gebruiken we als initialisatie $n_1n_1'=\\bar{N}$\n",
    "- De $diag(Q_t)^\\frac{-1}{2}$ is een diagonaal matrix waarbij de elementen op de diagonaal matrix hetzelfde zijn als die van $Q_t$ alleen dan nog in de wortel genomen\n",
    "- In andere woorden:\n",
    "$$diag(Q_t)^{-\\frac{1}{2}}=\\begin{pmatrix} \\sqrt(q_{11t}) & 0 \\\\ 0 & \\sqrt(q_{22t}) \\end{pmatrix}^{-1}, Q_t=\\begin{pmatrix} q_{11t} & q_{12t} \\\\ q_{21t} & q_{22t} \\end{pmatrix} $$\n",
    "- De log-likelihood wordt gemaximaliseerd wrt A, B, G, $\\nu$ waarbij A, B en G getallen zijn en die positief moeten zijn en $\\nu>2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_StudentADCC(mReturns,mH):\n",
    "    dA = 0.1\n",
    "    dB = 0.7\n",
    "    dG = 0.1\n",
    "    dNu = 4.2\n",
    "    vTheta = np.array([dA,dB,dG,dNu])\n",
    "    \n",
    "    def LL_Correlation_StudentADCC(vTheta,mReturns,mH):\n",
    "        dA = vTheta[0]\n",
    "        dB = vTheta[1]\n",
    "        dG = vTheta[2]\n",
    "        dNu = vTheta[3]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "        mZeros = np.zeros(mReturns.shape)\n",
    "        mDummy=(mEpsilon<mZeros)+mZeros\n",
    "        mN=mEpsilon*mDummy        \n",
    "\n",
    "        mS_sum = np.zeros((iDimension,iDimension))\n",
    "        mN_sum = np.zeros((iDimension,iDimension))\n",
    "        for i in range(iT):\n",
    "            vN_t=mN[:,i]\n",
    "            vN_t=vN_t.reshape((iDimension,1))\n",
    "            mN_sum += vN_t @ vN_t.T            \n",
    "            vEpsilon_t = mEpsilon[:,i]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            mS_sum += vEpsilon_t @ vEpsilon_t.T\n",
    "        \n",
    "        mS = mS_sum / iT\n",
    "        mN_bar=mN_sum / iT\n",
    "        mQ_old=np.copy(mS)\n",
    "        \n",
    "        dSum=0\n",
    "        for t in range(1,iT):\n",
    "            mD_t=np.diag(np.sqrt(mH[:,t]))\n",
    "            vEpsilon_lag=mEpsilon[:,t-1]\n",
    "            vEpsilon_lag=vEpsilon_lag.reshape((iDimension,1))\n",
    "            vEpsilon=mEpsilon[:,t]\n",
    "            vEpsilon=vEpsilon.reshape((iDimension,1))\n",
    "            vN_lag=mN[:,t-1]\n",
    "            vN_lag=vN_lag.reshape((iDimension,1))            \n",
    "            \n",
    "            mQ = (1-dA-dB) * mS - dG * mN_bar + dA * vEpsilon_lag @ vEpsilon_lag.T + dG * vN_lag @ vN_lag.T + dB * mQ_old \n",
    "            mQ_diagonal = np.sqrt(np.diagonal(mQ))\n",
    "            mR_t= inv(np.diag(mQ_diagonal)) @ mQ @ inv(np.diag(mQ_diagonal)) \n",
    "            \n",
    "            dLogLikelihood = gammaln((iDimension+dNu)/2) - gammaln(dNu/2) - iDimension/2 * np.log(np.pi*(dNu-2)) \\\n",
    "                            -0.5*np.log( det(mD_t)**2 ) - 0.5 * np.log( det(mR_t) ) - ( (dNu+iDimension)/2 ) * \\\n",
    "                            np.log(1+ ( ( vEpsilon.T @ inv(mR_t) @vEpsilon ) / (dNu-2) ) )\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "            mQ_old=mQ   \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0.0001, 0.9999), (0.0001,0.9999), (0.0001,0.9999),(2.1,50))\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_StudentADCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 3173.1956888161494\n",
      "            Iterations: 22\n",
      "            Function evaluations: 163\n",
      "            Gradient evaluations: 22\n",
      "[ 0.04127358  0.91498665  0.02541066  7.45767264]\n",
      "-3173.1956888161494\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(vParametersADCC,LL_Correlation_ADCC,success_Corr_ADCC)=Parameters_Correlation_StudentADCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(vParametersADCC)\n",
    "print(LL_Correlation_ADCC)\n",
    "print(success_Corr_ADCC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
