{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In dit script gaan we het CCC model en het DCC model schatten met normaalverdeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de cel hier onder te runnen moet er een package geinstalleerd worden via anaconda prompt. Deze package zorgt ervoor dat we functies uit andere scripts kunnen gerbuiken in dit script.\n",
    "<break>\n",
    "Tik het volgende in anaconda prompt:\n",
    "<br \\>\n",
    "**pip install ipynb**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import det\n",
    "from pandas_datareader import data as wb\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.Dataset import getdata\n",
    "from ipynb.fs.full.Dataset import getreturns\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de GARCH modellen te schatten heb ik mijn in-sample dataset nodig. Mijn in-sample dataset is vanaf 2010 tot en met 2015. Hier gebruik ik een functie die is geschreven in een ander script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getreturns()\n",
    "mInSampleReturns = df.loc[:\"2015\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de CCC de DCC modellen te schatten kan de log-likelihood opgedeeld worden in 2 delen.\n",
    "- Schat de GARCH(1,1) modellen los van elkaar.\n",
    "- schat daarna de correlatie term\n",
    "\n",
    "<break>\n",
    "De multivariate normal distribution van de GARCH modellen zien er als volgt uit:\n",
    "\n",
    "$$-\\frac{1}{2}\\sum_{t=2}^{T}(n\\log(2\\pi)+2\\log|D_t|+y_t'D_t^{-1}D_t^{-1}y_t)$$\n",
    "Dit is gelijk aan de som van de individuele GARCH modellen.\n",
    "<break>\n",
    "In de cel hieronder is een functie geschreven om een losse GARCH(1,1) model te schatten. De parameters die we hierbij moeten schatten zijn:\n",
    "\n",
    "- [$\\omega,\\alpha,\\beta$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_GARCH_Normal(vReturns):\n",
    "    dOmega = 0.1\n",
    "    dAlpha = 0.1\n",
    "    dBeta = 0.8    \n",
    "    vTheta = np.array([dOmega, dAlpha, dBeta])\n",
    "    \n",
    "    def LL_GARCH_Normal(vTheta,returns):\n",
    "        dOmega = vTheta[0]\n",
    "        dAlpha = vTheta[1]\n",
    "        dBeta  = vTheta[2]\n",
    "        iT=len(returns)\n",
    "        vH=np.zeros(iT)\n",
    "        \n",
    "        for t in range(iT):\n",
    "            if t == 0:\n",
    "                vH[t] = np.var(returns) \n",
    "            else:\n",
    "                vH[t] = dOmega + dAlpha*returns[t-1]**2 + dBeta * vH[t-1]    \n",
    "        \n",
    "        vLogPdf = -0.5 * np.log( 2 * np.pi * vH[1:] ) - 0.5 * ( returns[1:]**2 / vH[1:] )\n",
    "        return -np.sum(vLogPdf)\n",
    "    \n",
    "    def Optimizer(returns, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0, 1), (0, 1), (0, 1))\n",
    "    result=Optimizer(vReturns, vTheta, LL_GARCH_Normal, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wordt de eerste parameters en de log-likelihood van een losse GARCH model verkregen van de CAC40. De volgorde van de parameters is:\n",
    "- [$\\omega,\\alpha,\\beta$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2516.193369258651\n",
      "            Iterations: 12\n",
      "            Function evaluations: 68\n",
      "            Gradient evaluations: 12\n",
      "[ 0.05195353  0.09350152  0.87921127]\n",
      "-2516.193369258651\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter1_N,likelihood1_N,success1_N)=Parameters_GARCH_Normal(np.array(mInSampleReturns.iloc[:,0]))\n",
    "print(parameter1_N)\n",
    "print(likelihood1_N)\n",
    "print(success1_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wordt de eerste parameters en de log-likelihood van een losse GARCH model verkregen van de AEX. De volgorde van de parameters is:\n",
    "- [$\\omega,\\alpha,\\beta$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 2238.592048513497\n",
      "            Iterations: 12\n",
      "            Function evaluations: 69\n",
      "            Gradient evaluations: 12\n",
      "[ 0.03347424  0.09929269  0.8768056 ]\n",
      "-2238.592048513497\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(parameter2_N,likelihood2_N,success2_N)=Parameters_GARCH_Normal(np.array(mInSampleReturns.iloc[:,1]))\n",
    "print(parameter2_N)\n",
    "print(likelihood2_N)\n",
    "print(success2_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In de functie Hieronder wordt voor de $\\sigma_t^2$ van de losse garch modellen verkregen. Deze zijn nodig als we de log-likelihood van de correlatie term willen berekenen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeSigma2GARCH(vTheta1_N,vTheta2_N,mReturns):\n",
    "    iT = mReturns.shape[1]\n",
    "    iDimension = mReturns.shape[0]\n",
    "    mH = np.zeros((iDimension,iT))\n",
    "    dOmega1 = vTheta1_N[0]\n",
    "    dOmega2 = vTheta2_N[0]\n",
    "    dAlpha1 = vTheta1_N[1]\n",
    "    dAlpha2 = vTheta2_N[1]\n",
    "    dBeta1 = vTheta1_N[2]\n",
    "    dBeta2 = vTheta2_N[2]\n",
    "    for t in range(iT):\n",
    "        if t==0:\n",
    "            mH[0,t]=np.var(mReturns[0,:])\n",
    "            mH[1,t]=np.var(mReturns[1,:])\n",
    "        else:\n",
    "            mH[0,t]=dOmega1 + dAlpha1 * mReturns[0,t-1]**2 + dBeta1 * mH[0,t-1]\n",
    "            mH[1,t]=dOmega2 + dAlpha2 * mReturns[1,t-1]**2 + dBeta2 * mH[1,t-1]\n",
    "    return mH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mSigma2=ComputeSigma2GARCH(parameter1_N,parameter2_N,np.array(mInSampleReturns).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder maximaliseren we de log-likelihood van de correlatie term van het CCC model. \n",
    "De log-likelihood van de correlatie term ziet er als volgt uit:\n",
    "$$-\\frac{1}{2}\\sum_{t=2}^{T}(\\log|R|+\\epsilon_t'R^{-1}\\epsilon_t-\\epsilon_t'\\epsilon_t)$$\n",
    "- waarbij R is gedefinieerd als:\n",
    "$$R=\\begin{pmatrix} 1 & \\rho_{12} \\\\ \\rho_{12} & 1 \\end{pmatrix}$$\n",
    "- $\\epsilon_t$ als:\n",
    "$$\\epsilon_t=\\begin{pmatrix} \\epsilon_{1t} \\\\ \\epsilon_{2t}\\end{pmatrix}$$\n",
    "- $\\epsilon_{it}$ is verkregen door:\n",
    "$$\\epsilon_{it}=\\frac{y_{it}}{\\sigma_{it}}$$\n",
    "De log-likelihood willen we maximaliseren wrt $\\rho_{12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_NormalCCC(mReturns,mH):\n",
    "    dRho12 = 0\n",
    "    vTheta = np.array([dRho12])\n",
    "    \n",
    "    def LL_Correlation_NormalCCC(vTheta,mReturns,mH):\n",
    "        dRho12 = vTheta[0]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "        mR = np.ones((iDimension,iDimension))\n",
    "        mR[1,0] = dRho12\n",
    "        mR[0,1] = dRho12\n",
    "        \n",
    "        dSum=0\n",
    "        \n",
    "        for t in range(1,iT):\n",
    "            vEpsilon_t = mEpsilon[:,t]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            dLogLikelihood = -0.5 * (np.log(det(mR))+ vEpsilon_t.T @ inv(mR) @ vEpsilon_t - vEpsilon_t.T @ vEpsilon_t)\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "  \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((-1, 0.9999999),)\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_NormalCCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1489.8786032511491\n",
      "            Iterations: 29\n",
      "            Function evaluations: 108\n",
      "            Gradient evaluations: 28\n",
      "[ 0.92608184]\n",
      "1489.8786032511491\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(dRho,LL_Correlation_N,success_Corr_N)=Parameters_Correlation_NormalCCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(dRho)\n",
    "print(LL_Correlation_N)\n",
    "print(success_Corr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier gaan we de correlatie term van het DCC model schatten. De log-likelihood ziet er als volgt uit:\n",
    "$$-\\frac{1}{2}\\sum_{t=2}^{T}(\\log|R_t|+\\epsilon_t'R_t^{-1}\\epsilon_t-\\epsilon_t'\\epsilon_t)$$\n",
    "- Waarbij $R_t$ is gedefinieerd als:\n",
    "$$ R_t=\\text{diag}(Q_t)^{\\frac{-1}{2}}Q_t\\text{diag}(Q_t)^{\\frac{-1}{2}}$$\n",
    "- Q_t is gedefinieerd als:\n",
    "$$Q_t=(1-A-B)S + A\\epsilon_{t-1}\\epsilon_{t-1}' + BQ_{t-1}$$\n",
    "-S is gedefinieerd als:\n",
    "$$S=\\frac{1}{T}\\sum_{t=1}^{T}\\epsilon_t\\epsilon_t'$$\n",
    "verder gebruik ik als initialisatie van $Q_1=S$\n",
    "<break>\n",
    "- De $diag(Q_t)^\\frac{-1}{2}$ is een diagonaal matrix waarbij de elementen op de diagonaal matrix hetzelfde zijn als die van $Q_t$ alleen dan nog in de wortel genomen\n",
    "- In andere woorden:\n",
    "$$diag(Q_t)^{-\\frac{1}{2}}=\\begin{pmatrix} \\sqrt(q_{11t}) & 0 \\\\ 0 & \\sqrt(q_{22t}) \\end{pmatrix}^{-1}, Q_t=\\begin{pmatrix} q_{11t} & q_{12t} \\\\ q_{21t} & q_{22t} \\end{pmatrix} $$\n",
    "- De log-likelihood wordt gemaximaliseerd wrt A en B waarbij A en B getallen zijn en ze moeten positief zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_NormalDCC(mReturns,mH):\n",
    "    dA = 0.1\n",
    "    dB = 0.7\n",
    "    vTheta = np.array([dA,dB])\n",
    "    \n",
    "    def LL_Correlation_NormalDCC(vTheta,mReturns,mH):\n",
    "        dA = vTheta[0]\n",
    "        dB = vTheta[1]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "\n",
    "        mS_sum = np.zeros((iDimension,iDimension))\n",
    "        for i in range(iT):\n",
    "            vEpsilon_t = mEpsilon[:,i]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            mS_sum += vEpsilon_t @ vEpsilon_t.T\n",
    "        \n",
    "        mS = mS_sum / iT\n",
    "        mQ_old=np.copy(mS)\n",
    "        \n",
    "        dSum=0\n",
    "        for t in range(1,iT):\n",
    "            vEpsilon_lag=mEpsilon[:,t-1]\n",
    "            vEpsilon_lag=vEpsilon_lag.reshape((iDimension,1))\n",
    "            vEpsilon=mEpsilon[:,t]\n",
    "            vEpsilon=vEpsilon.reshape((iDimension,1))\n",
    "            \n",
    "            mQ = (1-dA-dB) * mS + dA * vEpsilon_lag @ vEpsilon_lag.T + dB * mQ_old \n",
    "            mQ_diagonal = np.sqrt(np.diagonal(mQ))\n",
    "            mR_t= inv(np.diag(mQ_diagonal)) @ mQ @ inv(np.diag(mQ_diagonal)) \n",
    "            \n",
    "            dLogLikelihood = -0.5 * (np.log(det(mR_t))+ vEpsilon.T @ inv(mR_t) @ vEpsilon - vEpsilon.T @ vEpsilon)\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "            mQ_old=mQ   \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0.0001, 0.9999), (0.0001,0.9999))\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_NormalDCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1536.4081115935837\n",
      "            Iterations: 13\n",
      "            Function evaluations: 63\n",
      "            Gradient evaluations: 13\n",
      "[ 0.06556189  0.88592729]\n",
      "1536.4081115935837\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(vParametersDCC,LL_Correlation_DCC,success_Corr_DCC)=Parameters_Correlation_NormalDCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(vParametersDCC)\n",
    "print(LL_Correlation_DCC)\n",
    "print(success_Corr_DCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier gaan we de correlatie term van het DCC model schatten. De log-likelihood ziet er als volgt uit:\n",
    "$$-\\frac{1}{2}\\sum_{t=2}^{T}(\\log|R_t|+\\epsilon_t'R_t^{-1}\\epsilon_t-\\epsilon_t'\\epsilon_t)$$\n",
    "- Waarbij $R_t$ is gedefinieerd als:\n",
    "$$ R_t=\\text{diag}(Q_t)^{\\frac{-1}{2}}Q_t\\text{diag}(Q_t)^{\\frac{-1}{2}}$$\n",
    "- Q_t is gedefinieerd als:\n",
    "$$Q_t=(1-A-B)S -G\\bar{N} + A\\epsilon_{t-1}\\epsilon_{t-1}' + Gn_{t-1}n_{t-1}' + BQ_{t-1}$$\n",
    "- S is gedefinieerd als:\n",
    "$$S=\\frac{1}{T}\\sum_{t=1}^{T}\\epsilon_t\\epsilon_t'$$\n",
    "verder gebruik ik als initialisatie voor $Q_1=S$\n",
    "<break>\n",
    "- n_{t-1} is gedefinieerd als: \n",
    "$$\n",
    "n_{t-1}=\\mathbb{1}(\\epsilon_{t-1})\\odot \\epsilon_{t-1}\n",
    "\\\\\n",
    "\\mathbb{1}=\\begin{cases}\n",
    "1&\\text{if $\\epsilon_{t-1}<0$}\\\\\n",
    "0&\\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "- Hierbij is $\\bar{N}$ gedefinieerd als:\n",
    "$$\\bar{N}=\\frac{1}{T}\\sum_{t=1}^{T}n_tn_t'\n",
    "$$\n",
    "Verder gebruiken we als initialisatie $n_1n_1'=\\bar{N}$\n",
    "- De $diag(Q_t)^\\frac{-1}{2}$ is een diagonaal matrix waarbij de elementen op de diagonaal matrix hetzelfde zijn als die van $Q_t$ alleen dan nog in de wortel genomen\n",
    "- In andere woorden:\n",
    "$$diag(Q_t)^{-\\frac{1}{2}}=\\begin{pmatrix} \\sqrt(q_{11t}) & 0 \\\\ 0 & \\sqrt(q_{22t}) \\end{pmatrix}^{-1}, Q_t=\\begin{pmatrix} q_{11t} & q_{12t} \\\\ q_{21t} & q_{22t} \\end{pmatrix} $$\n",
    "- De log-likelihood wordt gemaximaliseerd wrt A, B, G waarbij A, B en G getallen zijn en ze moeten allemaal positief zijn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Parameters_Correlation_NormalADCC(mReturns,mH):\n",
    "    dA = 0.1\n",
    "    dB = 0.7\n",
    "    dG = 0.1\n",
    "    vTheta = np.array([dA,dB,dG])\n",
    "    \n",
    "    def LL_Correlation_NormalADCC(vTheta,mReturns,mH):\n",
    "        dA = vTheta[0]\n",
    "        dB = vTheta[1]\n",
    "        dG = vTheta[2]\n",
    "        iT = mReturns.shape[1]\n",
    "        iDimension = len(mReturns)\n",
    "        mEpsilon = mReturns/np.sqrt(mH)\n",
    "        mZeros = np.zeros(mReturns.shape)\n",
    "        mDummy=(mEpsilon<mZeros)+mZeros\n",
    "        mN=mEpsilon*mDummy\n",
    "        \n",
    "        mS_sum = np.zeros((iDimension,iDimension))\n",
    "        mN_sum = np.zeros((iDimension,iDimension))\n",
    "        for i in range(iT):\n",
    "            vN_t=mN[:,i]\n",
    "            vN_t=vN_t.reshape((iDimension,1))\n",
    "            mN_sum += vN_t @ vN_t.T\n",
    "            vEpsilon_t = mEpsilon[:,i]\n",
    "            vEpsilon_t = vEpsilon_t.reshape((iDimension,1))\n",
    "            mS_sum += vEpsilon_t @ vEpsilon_t.T\n",
    "        \n",
    "        mS = mS_sum / iT\n",
    "        mN_bar=mN_sum / iT\n",
    "        mQ_old=np.copy(mS)\n",
    "        \n",
    "        dSum=0\n",
    "        for t in range(1,iT):\n",
    "            vEpsilon_lag=mEpsilon[:,t-1]\n",
    "            vEpsilon_lag=vEpsilon_lag.reshape((iDimension,1))\n",
    "            vEpsilon=mEpsilon[:,t]\n",
    "            vEpsilon=vEpsilon.reshape((iDimension,1))\n",
    "            vN_lag=mN[:,t-1]\n",
    "            vN_lag=vN_lag.reshape((iDimension,1))\n",
    "            \n",
    "            mQ = (1-dA-dB) * mS - dG * mN_bar + dA * vEpsilon_lag @ vEpsilon_lag.T + dG * vN_lag @ vN_lag.T + dB * mQ_old \n",
    "            mQ_diagonal = np.sqrt(np.diagonal(mQ))\n",
    "            mR_t= inv(np.diag(mQ_diagonal)) @ mQ @ inv(np.diag(mQ_diagonal)) \n",
    "            \n",
    "            dLogLikelihood = -0.5 * (np.log(det(mR_t))+ vEpsilon.T @ inv(mR_t) @ vEpsilon - vEpsilon.T @ vEpsilon)\n",
    "            dSum += np.asscalar(dLogLikelihood)\n",
    "            mQ_old=mQ   \n",
    "        return -dSum\n",
    "    \n",
    "    def Optimizer(returns, mH, initials, function, bnds):\n",
    "        result = minimize(function, initials, args=(returns,mH), \\\n",
    "                          options ={'eps':1e-09, 'disp': True, 'maxiter':200}, method='SLSQP',bounds=bnds)\n",
    "        return result\n",
    "    bounds = ((0.0001, 0.9999), (0.0001,0.9999), (0.00001,0.9999))\n",
    "    result=Optimizer(mReturns, mH, vTheta, LL_Correlation_NormalADCC, bounds)\n",
    "    return result.x, -result.fun, result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -1536.7784450693255\n",
      "            Iterations: 13\n",
      "            Function evaluations: 80\n",
      "            Gradient evaluations: 13\n",
      "[ 0.05261769  0.89170114  0.01877666]\n",
      "1536.7784450693255\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "(vParamtersADCC,LL_Correlation_ADCC,success_Corr_ADCC)=Parameters_Correlation_NormalADCC(np.array(mInSampleReturns).T,mSigma2)\n",
    "print(vParamtersADCC)\n",
    "print(LL_Correlation_ADCC)\n",
    "print(success_Corr_ADCC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
